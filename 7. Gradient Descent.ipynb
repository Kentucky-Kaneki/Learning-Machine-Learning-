{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6hWGLBrdoVCawvbpSZTFH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"C_mL6IUhET2v","executionInfo":{"status":"ok","timestamp":1758774592367,"user_tz":-330,"elapsed":2333,"user":{"displayName":"JAYARAM SOMASI","userId":"13122510142247926373"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-YEuz-8C_z-x","executionInfo":{"status":"ok","timestamp":1758774666522,"user_tz":-330,"elapsed":43,"user":{"displayName":"JAYARAM SOMASI","userId":"13122510142247926373"}}},"outputs":[],"source":["train_data = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n","test_data = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")\n","\n","test_data.drop(columns=['latitude', 'longitude'], axis=1, inplace=True)\n","train_data.drop(columns=['latitude', 'longitude'], axis=1, inplace=True)\n","\n","feature_cols = [\n","    'housing_median_age',\n","    'total_rooms',\n","    'total_bedrooms',\n","    'population',\n","    'households',\n","    'median_income'\n","]\n","\n","X_train = train_data[feature_cols]\n","y_train = train_data['median_house_value']\n","\n","X_test = test_data[feature_cols]\n","y_test = test_data['median_house_value']"]},{"cell_type":"code","source":["scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)\n","\n","# Add a bias column (intercept term) to X_train and X_test\n","X_train = np.c_[np.ones(X_train.shape[0]), X_train]  # Add a column of ones to the training data\n","X_test = np.c_[np.ones(X_test.shape[0]), X_test]  # Add a column of ones to the test data\n","\n","# Gradient Descent Algorithm\n","def gradient_descent(X, y, learning_rate=0.01, epochs=1000):\n","    m = len(y)  # Number of training examples\n","    theta = np.zeros(X.shape[1])  # Initialize theta (parameters) with zeros\n","\n","    # Cost function for linear regression (Mean Squared Error)\n","    def cost_function(X, y, theta):\n","        predictions = X.dot(theta)  # Predictions\n","        cost = (1 / (2 * m)) * np.sum((predictions - y) ** 2)  # MSE cost\n","        return cost\n","\n","    # Perform gradient descent\n","    for epoch in range(epochs):\n","        predictions = X.dot(theta)\n","        error = predictions - y\n","        gradient = (1 / m) * X.T.dot(error)  # Compute the gradient\n","        theta -= learning_rate * gradient  # Update theta\n","\n","        # Print cost every 100 epochs\n","        if epoch % 100 == 0:\n","            cost = cost_function(X, y, theta)\n","            print(f\"Epoch {epoch}, Cost: {cost:.4f}\")\n","\n","    return theta"],"metadata":{"id":"A-yEPqgXE2r9","executionInfo":{"status":"ok","timestamp":1758774669363,"user_tz":-330,"elapsed":11,"user":{"displayName":"JAYARAM SOMASI","userId":"13122510142247926373"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Train the model using gradient descent\n","theta = gradient_descent(X_train, y_train, learning_rate=0.001, epochs=3000)\n","\n","# Making predictions on the test set\n","y_pred = X_test.dot(theta)\n","\n","# Evaluate the model (Mean Squared Error on test set)\n","mse = np.mean((y_pred - y_test) ** 2)\n","print(f\"Mean Squared Error on Test Set: {mse:.4f}\")\n","\n","# You can also use R-squared to evaluate the model\n","ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n","ss_residual = np.sum((y_test - y_pred) ** 2)\n","r_squared = 1 - (ss_residual / ss_total)\n","print(f\"R-squared on Test Set: {r_squared:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maeb-fMLIzVs","executionInfo":{"status":"ok","timestamp":1758774956865,"user_tz":-330,"elapsed":804,"user":{"displayName":"JAYARAM SOMASI","userId":"13122510142247926373"}},"outputId":"52aafc98-3e3e-442e-f3f6-017fc4a74ccc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Cost: 28162694849.4820\n","Epoch 100, Cost: 23650253084.0323\n","Epoch 200, Cost: 19957293749.3789\n","Epoch 300, Cost: 16933151471.3168\n","Epoch 400, Cost: 14455664619.6447\n","Epoch 500, Cost: 12425372165.7447\n","Epoch 600, Cost: 10761102554.5979\n","Epoch 700, Cost: 9396519413.3354\n","Epoch 800, Cost: 8277366465.7691\n","Epoch 900, Cost: 7359246058.5461\n","Epoch 1000, Cost: 6605816574.1077\n","Epoch 1100, Cost: 5987324408.9803\n","Epoch 1200, Cost: 5479405919.7043\n","Epoch 1300, Cost: 5062108508.9684\n","Epoch 1400, Cost: 4719090202.1267\n","Epoch 1500, Cost: 4436964889.7197\n","Epoch 1600, Cost: 4204766582.5177\n","Epoch 1700, Cost: 4013510967.0530\n","Epoch 1800, Cost: 3855836542.4410\n","Epoch 1900, Cost: 3725710862.5272\n","Epoch 2000, Cost: 3618190049.6522\n","Epoch 2100, Cost: 3529221902.6787\n","Epoch 2200, Cost: 3455484683.4709\n","Epoch 2300, Cost: 3394255105.8792\n","Epoch 2400, Cost: 3343300228.6245\n","Epoch 2500, Cost: 3300788916.3641\n","Epoch 2600, Cost: 3265219320.8502\n","Epoch 2700, Cost: 3235359478.4160\n","Epoch 2800, Cost: 3210198647.1787\n","Epoch 2900, Cost: 3188907438.6610\n","Mean Squared Error on Test Set: 6265711788.7607\n","R-squared on Test Set: 0.5102\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oBkVsm9HJLCR"},"execution_count":null,"outputs":[]}]}